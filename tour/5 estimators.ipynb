{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ce9374-515b-4f1b-827c-dddba7e455f3",
   "metadata": {},
   "source": [
    "### [**Responsible AI Mitigation Library**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/)\n",
    "\n",
    "<details> \n",
    "<summary>Encoders</summary>\n",
    "  \n",
    "  [**Link to Encoders**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/encoder/encoder.html)\n",
    "    The Encoders API allows for ordinal or one-hot encoding of categorical features.\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.EncoderOrdinal(df: Optional[Union[DataFrame, ndarray]] = None, col_encode: Optional[list] = None, categories: Union[dict, str] = 'auto', unknown_err: bool = False, unknown_value: Union[int, float] = -1, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**One Hot Encoding**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/encoder/ordinal.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.EncoderOHE(df: Optional[Union[DataFrame, ndarray]] = None, col_encode: Optional[list] = None, drop: bool = True, unknown_err: bool = True, verbose: bool = True\n",
    "  ```\n",
    "</details>\n",
    "\n",
    "<details> \n",
    "<summary>Feature Selection</summary>\n",
    "\n",
    "[Link to Feature Selection](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/feat_sel/feat_sel.html)\n",
    "The Feature Selection API enables selecting a subset of features that are the most informative for the prediction task.\n",
    "\n",
    "  \n",
    "  [**Sequential Feature Selection**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/feat_sel/seq.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.SeqFeatSelection(df: Optional[Union[DataFrame, ndarray]] = None, label_col: Optional[str] = None, X: Optional[Union[DataFrame, ndarray]] = None, y: Optional[Union[DataFrame, ndarray]] = None, transform_pipe: Optional[list] = None, in_place: bool = False, regression: Optional[bool] = None, estimator: Optional[BaseEstimator] = None, n_feat: Union[int, str, tuple] = 'best', fixed_cols: Optional[list] = None, cv: int = 3, scoring: Optional[str] = None, forward: bool = True, save_json: bool = False, json_summary: str = 'seq_feat_summary.json', n_jobs: int = 1, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Feature Selection via Gradient Boosting**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/feat_sel/catboost.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.CatBoostSelection(df: Optional[Union[DataFrame, ndarray]] = None, label_col: Optional[str] = None, X: Optional[Union[DataFrame, ndarray]] = None, y: Optional[Union[DataFrame, ndarray]] = None, transform_pipe: Optional[list] = None, regression: Optional[bool] = None, estimator: Optional[Union[CatBoostClassifier, CatBoostRegressor]] = None, in_place: bool = False, catboost_log: bool = True, catboost_plot: bool = False, test_size: float = 0.2, cat_col: Optional[list] = None, n_feat: Optional[int] = None, fixed_cols: Optional[list] = None, algorithm: str = 'loss', steps: int = 1, save_json: bool = False, json_summary: str = 'cb_feat_summary.json', verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Feature Selection via Removing Correlated Features**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/feat_sel/correlation.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.CorrelatedFeatures(df: Optional[Union[DataFrame, ndarray]] = None, label_col: Optional[str] = None, X: Optional[Union[DataFrame, ndarray]] = None, y: Optional[Union[DataFrame, ndarray]] = None, transform_pipe: Optional[list] = None, in_place: bool = False, cor_features: Optional[list] = None, method_num_num: list = ['spearman'], num_corr_th: float = 0.85, num_pvalue_th: float = 0.05, method_num_cat: str = 'model', levene_pvalue: float = 0.01, anova_pvalue: float = 0.05, omega_th: float = 0.9, jensen_n_bins: Optional[int] = None, jensen_th: float = 0.8, model_metrics: list = ['f1', 'auc'], metric_th: float = 0.9, method_cat_cat: str = 'cramer', cat_corr_th: float = 0.85, cat_pvalue_th: float = 0.05, tie_method: str = 'missing', save_json: bool = True, json_summary: str = 'summary.json', json_corr: str = 'corr_pairs.json', json_uncorr: str = 'uncorr_pairs.json', compute_exact_matches: bool = True, verbose: bool = True)\n",
    "  ```\n",
    "</details>\n",
    "\n",
    "<details> \n",
    "<summary>Imputers</summary>\n",
    "\n",
    "[Link to Imputers](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/imputer/imputer.html)\n",
    "The Imputer API enables a simple approach for replacing missing values across several columns with different parameters, simultaneously replacing with the mean, median, most constant, or most frequent value in a dataset.\n",
    "\n",
    "  \n",
    "  [**Basic Imputation**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/imputer/basic.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.BasicImputer(df: Optional[Union[DataFrame, ndarray]] = None, col_impute: Optional[list] = None, categorical: Optional[dict] = None, numerical: Optional[dict] = None, specific_col: Optional[dict] = None, verbose: bool = True)\n",
    "  ```\n",
    "</details>\n",
    "\n",
    "<details> \n",
    "<summary>Sampling</summary>\n",
    "\n",
    "[Link to Sampling](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/sampler/sampler.html)\n",
    "The Sampling API enables data augmentation by rebalancing existing data or synthesizing new data.\n",
    "\n",
    "\n",
    "  [**Data Rebalance**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/sampler/rebalance.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.Rebalance(df: Optional[Union[DataFrame, ndarray]] = None, rebalance_col: Optional[str] = None, X: Optional[Union[DataFrame, ndarray]] = None, y: Optional[Union[DataFrame, ndarray]] = None, transform_pipe: Optional[list] = None, in_place: bool = False, cat_col: Optional[list] = None, strategy_over: Optional[Union[str, dict, float]] = None, k_neighbors: int = 4, over_sampler: Union[BaseSampler, bool] = True, strategy_under: Optional[Union[str, dict, float]] = None, under_sampler: Union[BaseSampler, bool] = False, n_jobs: int = 1, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Data Synthesis**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/sampler/synthesizer.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.Synthesizer(df: Optional[DataFrame] = None, label_col: Optional[str] = None, X: Optional[DataFrame] = None, y: Optional[DataFrame] = None, transform_pipe: Optional[list] = None, in_place: bool = False, model: Union[BaseTabularModel, str] = 'ctgan', epochs: int = 50, save_file: Optional[str] = None, load_existing: bool = True, verbose: bool = True)\n",
    "  ```\n",
    "</details>\n",
    "\n",
    "<details> \n",
    "<summary>Scalers</summary>\n",
    "\n",
    "[Link to Scalers](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/scaler.html)\n",
    "The Scaler API enables applying numerical scaling transformations to several features at the same time.\n",
    "\n",
    "  \n",
    "  [**Data Standardization Scaling**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/standard.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.DataStandardScaler(scaler_obj: Optional[StandardScaler] = None, df: Optional[Union[DataFrame, ndarray]] = None, exclude_cols: Optional[list] = None, include_cols: Optional[list] = None, transform_pipe: Optional[list] = None, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Min Max Scaling**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/minmax.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.DataMinMaxScaler(scaler_obj: Optional[MinMaxScaler] = None, df: Optional[Union[DataFrame, ndarray]] = None, exclude_cols: Optional[list] = None, include_cols: Optional[list] = None, transform_pipe: Optional[list] = None, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Quantile Transformer Scaling**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/quantile.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.DataQuantileTransformer(scaler_obj: Optional[QuantileTransformer] = None, df: Optional[Union[DataFrame, ndarray]] = None, exclude_cols: Optional[list] = None, include_cols: Optional[list] = None, transform_pipe: Optional[list] = None, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Power Transformer Scaling**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/power.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.DataPowerTransformer(scaler_obj: Optional[PowerTransformer] = None, df: Optional[Union[DataFrame, ndarray]] = None, exclude_cols: Optional[list] = None, include_cols: Optional[list] = None, transform_pipe: Optional[list] = None, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Robust Statistics Scaling**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/robust.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.DataRobustScaler(scaler_obj: Optional[RobustScaler] = None, df: Optional[Union[DataFrame, ndarray]] = None, exclude_cols: Optional[list] = None, include_cols: Optional[list] = None, transform_pipe: Optional[list] = None, verbose: bool = True))\n",
    "\n",
    "\n",
    "  ```\n",
    "  [**Data Normalization Scaling**](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/dataprocessing/scaler/normalize.html)\n",
    "\n",
    "  ```py\n",
    "  classdataprocessing.DataNormalizer(scaler_obj: Optional[Normalizer] = None, df: Optional[Union[DataFrame, ndarray]] = None, exclude_cols: Optional[list] = None, include_cols: Optional[list] = None, transform_pipe: Optional[list] = None, verbose: bool = True)\n",
    "  ```\n",
    "\n",
    "  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fcc486",
   "metadata": {},
   "source": [
    "# Assess income level predictions on adult census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12889d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import raimitigations.dataprocessing as dp\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd4647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def split_label(dataset, target_feature):\n",
    "    X = dataset.drop([target_feature], axis=1)\n",
    "    y = dataset[[target_feature]]\n",
    "    return X, y\n",
    "\n",
    "target_feature = 'income'\n",
    "categorical_features = ['workclass', 'education', 'marital-status',\n",
    "                        'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "\n",
    "train_data = pd.read_csv('data/adult-train.csv', skipinitialspace=True, header=0)\n",
    "test_data = pd.read_csv('data/adult-test-sample.csv', skipinitialspace=True, header=0)\n",
    "\n",
    "X_train_original, y_train = split_label(train_data, target_feature)\n",
    "X_test_original, y_test = split_label(test_data, target_feature)\n",
    "\n",
    "estimator = LGBMClassifier(random_state=0, n_estimators=5)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='constant', fill_value='?')),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    (\"estimator\", estimator)\n",
    "])\n",
    "pipe.fit(X_train_original, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca38e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(pipe, open(\"../uci_5_estimators\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854c7cc3-d1cd-4e5a-a18f-f374ed55a8de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponsibleAI started at http://localhost:5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<raiwidgets.responsibleai_dashboard.ResponsibleAIDashboard at 0x25da66a4370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai import RAIInsights\n",
    "rai_insights = RAIInsights(pipe, train_data, test_data, target_feature, 'classification',\n",
    "                           categorical_features=categorical_features)\n",
    "# Interpretability\n",
    "rai_insights.explainer.add()\n",
    "# Error Analysis\n",
    "rai_insights.error_analysis.add()\n",
    "rai_insights.compute()\n",
    "ResponsibleAIDashboard(rai_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576a707-3854-47a4-a6aa-a0aed415c6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
